data(ColonData)
library(MAMA)
install.packages("MAMA",dependencies=TRUE)
library(MAMA)
install.packages("multtest")
install.packages("RankProd")
quit()
install.packages("rmarkdown")
x=2
y=4
x %*% y
x * y
tmp<- x %*% y
class(tmp)
B = matrix(
c(2, 2, 2, 3, 3, 3),
nrow=3,
ncol=2)
B
C = matrix(
c(2, 2, 2, 3, 3, 3),
nrow=3,
ncol=2)
B %*% C
C = matrix(
c(2, 2,  3, 3),
nrow=2,
ncol=2)
C
B = matrix(
c(2, 2,  3, 3),
nrow=2,
ncol=2)
C
B
B %*% C
quit()
install.packages("rotationForest")
head(irsi)
head(iris)
dim(iris)
iris.split <- split(iris,as.factor(iris$Species))
iris.split
?split()
str(iris.split)
?colMean
?colMeans
iris.apply <- lapply(iris.split,function(x)colMeans(x[-5]))
head(iris.apply)
iris.combine <- do.call(rbind,iris.apply)
iris.combine
require(ROCR)
?performance
?treeresponse
??treeresponse
?predict
library(party)
?treeresponse
data(iris)
iris_features <- iris[1:4]
dist_eucl <- function(x1, x2) sqrt(sum((x1 - x2) ^ 2))
distances <- apply(iris_features, 1,function(x) dist_eucl(x, new_sample))
library(caret)
iris_numeric <- iris[1:4]
pp_unit <- preProcess(iris_numeric, method = c("range"))
iris_numeric_unit <- predict(pp_unit, iris_numeric)
iris_numeric_unit
pp_zscore <- preProcess(iris_numeric, method = c("center",
"scale"))
iris_numeric[1:3,]
?predict
iris_numeric_zscore <- predict(pp_zscore, iris_numeric)
iris_numeric_zscore
pp_Zscore[1:3:,]
pp_zscore[1:3:,]
pp_zscore
?preProcess
pp_boxcox <- preProcess(iris_numeric, method = c("BoxCox"))
iris_numeric_boxcox <- predict(pp_boxcox, iris_numeric)
install.packages("nnet")
quit()
library(tm)
path_to_neg_folder <- "C:/aclImdb/train/neg"
path_to_pos_folder <- "C:/aclImdb/train/pos"
nb_pos <- Corpus(DirSource(path_to_pos_folder), readerControl = list(language = "en"))
nb_neg <- Corpus(DirSource(path_to_neg_folder),readerControl = list(language = "en"))
nb_all <- c(nb_pos, nb_neg, recursive = T)
meta(nb_all[[1]])
ids <- sapply( 1 : length(nb_all), function(x) meta(nb_all[[x]], "id"))
head(ids)
scores <- as.numeric(sapply(ids, function(x) sub("[0-9]+_([0-9]+)\\.txt", "\\1", x)))
scores <- factor(ifelse(scores >= 5, "positive", "negative"))
nb_all <- tm_map(nb_all, content_transformer(removeNumbers))
nb_all <- tm_map(nb_all, content_transformer(removePunctuation))
nb_all <- tm_map(nb_all, content_transformer(tolower))
nb_all <- tm_map(nb_all, content_transformer(removeWords), stopwords("english"))
nb_all <- tm_map(nb_all, content_transformer(stripWhitespace))
nb_dtm <- DocumentTermMatrix(nb_all)
nb_dtm <- removeSparseTerms(x = nb_dtm, sparse = 0.99)
dim(nb_dtm)
inspect(nb_dtm[10:16, 1:6])
nb_dtm <- weightBin(nb_dtm)
nb_df <- as.data.frame(as.matrix(nb_dtm))
library(caret)
library(e1071)
set.seed(12345)
nb_sampling_vector <- createDataPartition(scores, p = 0.80, list = FALSE)
nb_df_train <- nb_df[nb_sampling_vector,]
nb_df_test <- nb_df[-nb_sampling_vector,]
scores_train = scores[nb_sampling_vector]
scores_test = scores[-nb_sampling_vector]
nb_model <- naiveBayes(nb_df_train, scores_train)
nb_train_predictions <- predict(nb_model, nb_df_train)
nb_test_predictions <- predict(nb_model, nb_df_test)
mean(nb_test_predictions == scores_test)
library("randomForest")
randomForest(nb_df_train, scores_train)
rf<- randomForest(nb_df_train, scores_train)
?predict
test_pred <- predict(rf, nb_test_predictions, type="prob")[,2]
test_pred <- predict(rf, nb_test_test, type="prob")[,2]
test_pred <- predict(rf, nb_df_test, type="prob")[,2]
test_pred
rf_test_predection <- predict(rf, nb_test_predictions, type="prob")[,2]
mean(rf_test_predictions == scores_test)
rf_test_predicction <- predict(rf, nb_test_predictions, type="prob")[,2]
rf_test_predicction <- predict(rf, nb_df_test, type="prob")[,2]
mean(rf_test_predictions == scores_test)
mean(rf_test_predicctions == scores_test)
mean(rf_test_predicction == scores_test)
rf_test_predicction
rf_test_predicction <- predict(rf, nb_df_test, type="class")[,2]
rf_test_prediction <- predict(rf, nb_df_test, type="class")
rf_test_prediction
mean(rf_test_prediction == scores_test)
rf_test_prediction
str(rf_test_prediction)
head(rf_test_prediction)
mean(rf_test_predictions == scores_test)
mean(rf_test_prediction == scores_test)
library(e1071)
?svm
SVM_model <- svm(nb_df_train, scores_train,type='C',kernel='radial',probability = FALSE)
SVM_test_prediction <- predict(SVM_model, nb_df_test,type="class")
mean(SVM_test_prediction == scores_test)
library(earth)
?earth
mars_model <-  earth(nb_df_train, scores_train)
mars_test_prediction <- predict(mars_model, nb_df_test,type="class")
mean(mars_test_prediction == scores_test)
library(gbm)
gbm_model = gbm(nb_df_train, scores_train,shrinkage=0.005 ,cv.folds=10)
?gbm
gbm_model = gbm(nb_df_train, scores_train)
gbm_model = gbm(nb_df_train, scores_train,distribution="gaussian",shrinkage=0.005 ,cv.folds=10)
nb_df_train[1:10]
length(nb_df_train)
nb_df_train[1:10,]
gbm_model = gbm(nb_df_train, scores_train,distribution="gaussian",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
vignette("caretTrain", package="caret")
library(caret)
vignette("caretTrain", package="caret")
gbm_model = gbm(nb_df_train, scores_train,distribution="multinominal",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
quit()
library(tm)
path_to_neg_folder <- "C:/aclImdb/train/neg"
path_to_pos_folder <- "C:/aclImdb/train/pos"
nb_pos <- Corpus(DirSource(path_to_pos_folder), readerControl = list(language = "en"))
nb_neg <- Corpus(DirSource(path_to_neg_folder),readerControl = list(language = "en"))
nb_all <- c(nb_pos, nb_neg, recursive = T)
meta(nb_all[[1]])
ids <- sapply( 1 : length(nb_all), function(x) meta(nb_all[[x]], "id"))
head(ids)
scores <- as.numeric(sapply(ids, function(x) sub("[0-9]+_([0-9]+)\\.txt", "\\1", x)))
scores <- factor(ifelse(scores >= 5, "positive", "negative"))
nb_all <- tm_map(nb_all, content_transformer(removeNumbers))
nb_all <- tm_map(nb_all, content_transformer(removePunctuation))
nb_all <- tm_map(nb_all, content_transformer(tolower))
nb_all <- tm_map(nb_all, content_transformer(removeWords), stopwords("english"))
nb_all <- tm_map(nb_all, content_transformer(stripWhitespace))
nb_dtm <- DocumentTermMatrix(nb_all)
nb_dtm <- removeSparseTerms(x = nb_dtm, sparse = 0.99)
dim(nb_dtm)
inspect(nb_dtm[10:16, 1:6])
nb_dtm <- weightBin(nb_dtm)
nb_df <- as.data.frame(as.matrix(nb_dtm))
nb_sampling_vector <- createDataPartition(scores, p = 0.80, list = FALSE)
nb_df_train <- nb_df[nb_sampling_vector,]
nb_df_test <- nb_df[-nb_sampling_vector,]
library(caret)
library(e1071)
set.seed(12345)
nb_sampling_vector <- createDataPartition(scores, p = 0.80, list = FALSE)
nb_df_train <- nb_df[nb_sampling_vector,]
nb_df_test <- nb_df[-nb_sampling_vector,]
names(nb_df_test)
names(nb_df_train)
scores_train = scores[nb_sampling_vector]
scores_train[1:10]
df_train$class <- scores_train
df_train <-  nb_df_train
df_train$class <- scores_train
names(df_train)
str(df_train)[1600:]
str(df_train)
fix()
fix(df_train)
? as.data.frame
df_train <-  as.data.frame(nb_df_train)
class(df_train)
df_train$class <- scores_train
str(df_train)
df_train$class[1:10]
library(gbm)
gbm_model = gbm(class~. data= df_train,distribution="multinominal",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
gbm_model = gbm(class~., data= df_train,distribution="multinominal",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
gbm_model = gbm(class~. data= df_train,distribution="pairwise",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
gbm_model = gbm(class~., data= df_train,distribution="pairwise",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
gbm_model = gbm(class~., data= df_train,distribution="bernoulli",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
gbm_model = gbm(class~., data= df_train,distribution="bernoulli",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)
head(df_train)
library(caret)
?colSums
dim(UCBAdmissions)
rowSums(UCBAdmissions)
str(UCBAdmissions)
dim(UCBAdmission)
dim(UCBAdmissions)
UCBAdmission
UCBAdmissions
class(UCBAdmission)
class(UCBAdmissions)
UCBAdmissions[1,1]
UCBAdmissions[1,1,1]
UCBAdmissions[1,1,2]
UCBAdmissions[1,1,3]
UCBAdmissions[1,1,4]
UCBAdmissions[1,1,5]
UCBAdmissions[1,1,6]
UCBAdmissions[1,1,7]
UCBAdmissions[1,2,1]
set.seed(17)
n <- 1000
x <- sample(c(0,1), n, replace=TRUE)
factor1 <- as.factor(floor(2*runif(n)))
factor2 <- as.factor(floor(3*runif(n)))
factor3 <- as.factor(floor(4*runif(n)))
factor1
factor2[1:20]
quit()
library(gbm)
boost <- gbm(class~. , data=df_train, distribution = 'gaussian',
n.trees = 5000,   interaction.depth = 4)
boost.pred <- predict (boost, df_test, n.trees=5000)
mean((boost.pred  == scores_test)
library(MASS)
attach(Boston)
library(gbm)
boost <- gbm(medv~. , data=train, distribution = 'gaussian', n.trees = 100,
interaction.depth = 4)
library(caret)
## Loading required package: lattice
## Loading required package: ggplot2
set.seed(123)
split <- createDataPartition(y=Boston$medv, p = 0.7, list=FALSE)
train <- Boston[split,]
test<- Boston[-split,]
library(gbm)
boost <- gbm(medv~. , data=train, distribution = 'gaussian', n.trees = 100,
interaction.depth = 4)
summary(boost)
boost.pred <- predict (boost, test, n.trees=5000)
mean((boost.pred - test$medv)^2)
boost.pred
set.seed(3719)
n <- 2000
#  Generate variables x1, ... x10
X <- matrix(rnorm(10*n), n, 10)
#  y = +1 if sum_i x_{ij}^2 > chisq median on 10 df
y <- rep(-1, n)
y[apply(X*X, 1, sum) > qchisq(.5, 10)] <- 1
#  Assign names to the columns of X:
dimnames(X)[[2]] <- c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10")
#  Convert to data.frame
train.data <- as.data.frame(X)
#  Add y
train.data$y <- y
#  Now repeat for 10000 test data
n <- 10000
X <- matrix(rnorm(10*n), n, 10)
y <- rep(-1, n)
y[apply(X*X, 1, sum) > qchisq(.5, 10)] <- 1
dimnames(X)[[2]] <- c("x1", "x2", "x3", "x4", "x5", "x6", "x7", "x8", "x9", "x10")
test.data <- as.data.frame(X)
test.data$y <- y
train.data2 <- train.data
train.data2$y[train.data2$y < 0] <- 0
test.data2 <- test.data
test.data2$y[test.data2$y < 0] <- 0
all.data2 <- rbind(train.data2, test.data2)
all.data2
library(gbm)
fit.gbm1 <- gbm(y ~ ., data=all.data2, dist="adaboost", n.tree = 400,
shrinkage = 1, train.fraction = (2/12))
summary(fit.gbm1)
confusion(predict(fit.gbm1, test.data2, n.trees = 69) > 0, test.data2$y > 0)
library(caret)
confusion(predict(fit.gbm1, test.data2, n.trees = 69) > 0, test.data2$y > 0)
confusion <- function(a, b){
tbl <- table(a, b)
mis <- 1 - sum(diag(tbl))/sum(tbl)
list(table = tbl, misclass.prob = mis)
}
confusion(predict(fit.gbm1, test.data2, n.trees = 69) > 0, test.data2$y > 0)
predict(fit.gbm1, test.data2, n.trees = 69)
predict(fit.gbm1, test.data2, n.trees = 69) >0
test.data2$y
library(caret)
installed.packages(caret)
installed.packages("caret")
packageDescription("caret")$Version
packageDescription("tm")$Version
packageDescription("e1071")$Version
packageDescription("randomForest")$Version
packageDescription("earth")$Version
quit()
setwd("C:/algorithmSelection/code")
library(manipulate)
df <- read.csv("residuals_compare.csv")
dat <- melt(df)
library(ggplot2)
dat <- melt(df)
library(reshape2)
dat <- melt(df)
str(df)
library(caret)
library(e1071)
library(ggplot2)
library(MASS)
library(gbm)
df <- read.csv("../data/Alldata.csv")
df <- df[-c(1:7,10,12:14)]
simpleMod <- dummyVars(~., data=df,levelsOnly= TRUE)
df <- predict(simpleMod, df)
df <- as.data.frame(df)
set.seed(215)
TrainRow <- createDataPartition(df[, ncol(df)], p = 0.7, list= FALSE)
trainData <- df[TrainRow,]
ctrl <- trainControl(method = "repeatedcv", repeats = 5,number=10)
trainX <- df[TrainRow,1:ncol(df)-1]
trainY<-df[TrainRow,ncol(df)]
testX <- df[-TrainRow, 1:ncol(df)-1]
observed <- df[-TrainRow,ncol(df)]
fit <- ctree(SAR~., data=trainData, controls=ctree_control(minsplit=2,minbucket=2,testtype="Univariate"))
library(rpart)
fit <- ctree(SAR~., data=trainData, controls=ctree_control(minsplit=2,minbucket=2,testtype="Univariate"))
library(party)
fit <- ctree(SAR~., data=trainData, controls=ctree_control(minsplit=2,minbucket=2,testtype="Univariate"))
CTree.pred <- predict(fit, testX)
# summarize accuracy
rmse <- mean((observed - CTree.pred)^2)
result <- cbind(observed,CTree.pred)
CTree.residual <- CTree.pred - observed
library(RWeka)
m5Tune <- train(trainX, trainY,
method = "M5",
trControl = trainControl(method = "cv"),
control = Weka_control(M = 10))
m5tree <- M5P(trainY ~ ., data = trainX,  control = Weka_control(M = 10))
fit <- M5P(SAR~., data=trainData)
M5P.pred <- predict(fit, testX)
rmse <- mean((observed - M5P.pred)^2)
result <- cbind(result,M5P.pred)
M5P.residual <- M5P.pred - observed
fit <- cubist(trainX, trainY)
Cubist.pred <- predict(fit, testX)
library(Cubist)
fit <- cubist(trainX, trainY)
Cubist.pred <- predict(fit, testX)
rmse <- mean((observed - Cubist.pred)^2)
set.seed(215)
library(kernlab)
svmRModel <- train(x = trainX,trainY,method = "svmRadial",preProc = c("center", "scale"), tuneLength = 10,trControl = trainControl(method = "cv"))
SVMR.pred <- predict(svmRModel, newdata = testX)
RMSE(SVMR.pred,observed)  #  RMSE : 1.393408
result <- cbind(result,SVMR.pred)
SVMR.residual <- SVMR.pred - observed
residuals <- cbind(residuals, SVMR.residual)
rm(SVMR.residual)
rm(SVMR.pred)
set.seed(215)
library(lars)
lars.fit <- lars(as.matrix(trainX),trainY,type=c("lasso"))
lars.Pred <- predict.lars(lars.fit,newx=as.matrix(testX),type="fit")
# get last model fit
last.fit <- dim(lars.Pred[4]$fit)[2]
predLars <- lars.Pred[4]$fit[,last.fit]
RMSE(predLars,observed)
result <- cbind(result,predLars)
lars.residual <- predLars - observed
residuals <- cbind(residuals, lars.residual)
rm(lars.residual)
rm(predLars)
rm(larsPred)
set.seed(215)
marsGrid <- expand.grid(.degree = 1:2, .nprune = 2:38)
marsTuned <- train(trainX, trainY, method = "earth",tuneGrid = marsGrid,trControl = trainControl(method = "cv"))
predMars <- predict(marsTuned,testX)
RMSE(predMars,observed)
result <- cbind(result,predMars)
mars_residual <- predMars - observed
residuals <- cbind(residuals, mars_residual)
rm(mars_residual)
rm(predMars)
write.table(result,file="c:/LearningAlgorithmForTask/comparePerformance.csv",sep=",",row.names=FALSE,col.names=TRUE)
write.table(residuals,file="c:/LearningAlgorithmForTask/residuals_Compare.csv",sep=",",row.names=FALSE,col.names=TRUE)
setwd("c:/LearningAlgorithmForTask")
library(reshape2)
df <- read.csv("residuals_compare.csv")
str(df)
head(df)
df <- read.csv("c:/AlgorithmSelection/residuals_compare.csv")
fit <- ctree(SAR~., data=trainData, controls=ctree_control(minsplit=2,minbucket=2,testtype="Univariate"))
CTree.pred <- predict(fit, testX)
result <- cbind(observed,CTree.pred)
CTree.residual <- CTree.pred - observed
residuals <-  as.data.frame(SVMR.residual)
residuals <-  as.data.frame(CTree.residual)
head(residuals)
m5tree <- M5P(trainY ~ ., data = trainX,  control = Weka_control(M = 10))
fit <- M5P(SAR~., data=trainData)
M5P.pred <- predict(fit, testX)
rmse <- mean((observed - M5P.pred)^2)
result <- cbind(result,M5P.pred)
M5P.residual <- M5P.pred - observed
residuals <- cbind(residuals, M5P.residual)
fit <- cubist(trainX, trainY)
Cubist.pred <- predict(fit, testX)
# summarize accuracy
rmse <- mean((observed - Cubist.pred)^2)
Cubist.residual <- Cubist.pred - observed
residuals <- cbind(residuals, Cubist.residual)
svmRModel <- train(x = trainX,trainY,method = "svmRadial",preProc = c("center", "scale"), tuneLength = 10,trControl = trainControl(method = "cv"))
SVMR.pred <- predict(svmRModel, newdata = testX)
RMSE(SVMR.pred,observed)  #  RMSE : 1.393408
result <- cbind(result,SVMR.pred)
SVMR.residual <- SVMR.pred - observed
residuals <- cbind(residuals, SVMR.residual)
str(residuals)
lars.fit <- lars(as.matrix(trainX),trainY,type=c("lasso"))
lars.Pred <- predict.lars(lars.fit,newx=as.matrix(testX),type="fit")
# get last model fit
last.fit <- dim(lars.Pred[4]$fit)[2]
predLars <- lars.Pred[4]$fit[,last.fit]
RMSE(predLars,observed)
cor.test(observed, predLars, method="spearman")
result <- cbind(result,predLars)
lars.residual <- predLars - observed
residuals <- cbind(residuals, lars.residual)
marsGrid <- expand.grid(.degree = 1:2, .nprune = 2:38)
marsTuned <- train(trainX, trainY, method = "earth",tuneGrid = marsGrid,trControl = trainControl(method = "cv"))
predMars <- predict(marsTuned,testX)
RMSE(predMars,observed)
result <- cbind(result,predMars)
write.table(result,file="c:/LearningAlgorithmForTask/comparePerformance.csv",sep=",",row.names=FALSE,col.names=TRUE)
write.table(residuals,file="c:/LearningAlgorithmForTask/residuals_Compare.csv",sep=",",row.names=FALSE,col.names=TRUE)
library(reshape2)
df<- residuals
str(df)
mars.residual <- predMars - observed
residuals <- cbind(residuals, mars.residual)
residuals
str(residuals)
CTree.residual[1:4]
write.table(residuals,file="c:/LearningAlgorithmForTask/residuals_Compare.csv",sep=",",row.names=FALSE,col.names=TRUE)
head(residuals)
setwd("c:/LearningAlgorithmForTask")
library(reshape2)
df <- read.csv("residuals_compare.csv")
str(df)
?melt
dat <- melt(df)
dat
pdf("residualHistogram.pdf", width=6, height=5)
p1 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'ModelTree.residual'),fill = "black", alpha = 0.2,binwidth=10) + ggtitle("Model Tree")
p2 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'CTree.residual'),fill = "black", alpha = 0.2,binwidth=10) + ggtitle("Conditional Tree") + scale_x_continuous(breaks=c(-20,-10,10,20))
p3 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'Cubist.residual'),fill = "black", alpha = 0.2,binwidth=10) +ggtitle("Cubist ") + scale_x_continuous(breaks=c(-20,-10,10,20))
p4 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'SVMR_residual'),fill = "black", alpha = 0.2,binwidth=10) +ggtitle("SVR residuals") + scale_x_continuous(breaks=c(-20,-10,10,20))
p5 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'lars_residual'),fill = "black", alpha = 0.2,binwidth=10) +ggtitle("Lars residuals") + scale_x_continuous(breaks=c(-20,-10,10,20))
p6 <- ggplot(dat,aes(x=value)) + geom_histogram(data=subset(dat,variable == 'mars_residual'),fill = "black", alpha = 0.2,binwidth=10) +ggtitle("mars residuals") + scale_x_continuous(breaks=c(-20,-10,10,20))
p<- grid.arrange(p1,p2, p3, p4,p5,p6, nrow=2)
print(p)
dev.off()
`
1
*
-
;
.
122
%%%
###
$
''
`
library(gridExtra)
p<- grid.arrange(p1,p2, p3, p4,p5,p6, nrow=2)
print(p)
dev.off()
pdf("residualHistogram.pdf", width=6, height=5)
p <- grid.arrange(p1,p2, p3, p4,p5,p6, nrow=2)
quit()
