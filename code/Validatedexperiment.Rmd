---
title: "LearningAlgorithm For data mining Task"
author: "TriDoan"
date: "Sunday, August 23, 2015"
output: html_document
---

Prepare to load corpus data 

```{r}
setwd("C:/aclImdb")
library(tm)

df_pos <- Corpus(DirSource("./train/pos"), readerControl = list(language = "en"))
df_neg <- Corpus(DirSource("./train/neg"),readerControl = list(language = "en"))
df <- c(df_pos, df_neg, recursive = T)

meta(df[[1]])test
ids <- sapply( 1 : length(df), function(x) meta(df[[x]], "id"))

head(ids)
scores <- as.numeric(sapply(ids, function(x) sub("[0-9]+_([0-9]+)\\.txt", "\\1", x)))
scores <- factor(ifelse(scores >= 5, "positive", "negative"))

df <- tm_map(df, content_transformer(removeNumbers))
df <- tm_map(df, content_transformer(removePunctuation))
df <- tm_map(df, content_transformer(tolower))
df <- tm_map(df, content_transformer(removeWords), stopwords("english"))
df <- tm_map(df, content_transformer(stripWhitespace))

df <- DocumentTermMatrix(df)
df <- removeSparseTerms(x = df, sparse = 0.99)

dim(df)
inspect(df[10:16, 1:6])


df <- weightBin(df)




```
Convert into data frame

```{r}
 df <- as.data.frame(as.matrix(df))
```
Load library
```{r}
library(caret)
library(e1071)
set.seed(12345)

```
Create train and test set

```{r}
Idx <- createDataPartition(scores, p = 0.80, list = FALSE)
df_train <- df[Idx,]
df_test <- df[-Idx,]


scores_train = scores[Idx]
scores_test = scores[-Idx]

df_train <-  as.data.frame(df_train)

df_train$class <- scores_train

 write.table(df,file="movieSentiments.csv",sep=",",row.names=FALSE,col.names=TRUE)    
```

Without further preprocessing data, using Naive Bayes we can achieve

accuracy =  0.8158

```{r}
start.time <- Sys.time()
nb_model <- naiveBayes(df_train[,-c(239)], scores_train)
#nb_train_predictions <- predict(nb_model, df_train[,-c(239)])

nb_test_predictions <- predict(nb_model, df_test)

time.taken <- Sys.time() - start.time
mean(nb_test_predictions == scores_test)

```
Now we check other model

1. Random Forest
accuracy = 0.834  2.381905 hours

```{r}
library("randomForest")
start.time <- Sys.time()
rf<- randomForest(df_train[,-c(239)], scores_train)
time.taken <- Sys.time() - start.time
rf_test_prediction <- predict(rf, df_test, type="class")
mean(rf_test_prediction == scores_test)
```

2. SVM

accuracy = 0.8578
```{r}

library(e1071)
start.time <- Sys.time()
SVM_model <- svm(df_train[,-c(239)], scores_train,type='C',kernel='radial',probability = FALSE)
SVM_test_prediction <- predict(SVM_model, df_test,type="class")
time.taken <- Sys.time() - start.time 
mean(SVM_test_prediction == scores_test)

```
3. Multivariate Adaptive Regression Splines

accuracy = 0.8188  14.98963 mins

```{r}
library(earth)
start.time <- Sys.time()
mars_model <-  earth(df_train[,-c(239)], scores_train)
mars_test_prediction <- predict(mars_model, df_test,type="class")
time.taken <- Sys.time() - start.time
mean(mars_test_prediction == scores_test)

```
Bagged Tree with caret 
```{r}
start.time <- Sys.time()
baggedModel <- train(class~., data=df_train, method="treebag", B=5,
train_control = trainControl(method="cv", number=10), prox=TRUE,allowParallel=TRUE)

BaggedTree.pred <- predict(baggedModel,newdata=df_test) 
time.taken <- end.time - start.time
confusionMatrix(BaggedTree.pred, scores_test)
```
Boost tree with gbm for regression

```{r}
library(gbm)
boost <- gbm(class~. , data=df_train[,-c(239)], distribution = 'gaussian', 
             n.trees = 5000,   interaction.depth = 4)

boost.pred <- predict (boost, df_test, n.trees=5000)
mean((boost.pred  == scores_test)
     
```
 Alternative, select parameters with caret package

```{r}
     
ctr <- trainControl(method = "cv", number = 10)

boost.caret <- train(class~., df_train,  method='bstTree',
                     preProc=c('center','scale'), trControl=ctr)
boost.caret.pred <- predict(boost.caret, df_test)


```
 gradient boost m

```{r}
library(gbm)
gbm_model = gbm(class~., data= df_train,distribution="bernoulli",interaction.depth=3,shrinkage=0.005 ,cv.folds=10)

best.iter <- gbm.perf(GBM_model,method="cv")

train_pred <- predict.gbm(GBM_model,trainset,best.iter)
test_pred <- predict.gbm(GBM_model,testset,best.iter)

```
Test AUC multiple classifier 
```{r}
library(ROCR)
data(ROCR.hiv)
attach(ROCR.hiv)
pred.svm <- prediction(hiv.svm$predictions, hiv.svm$labels)
perf.svm <- performance(pred.svm, 'tpr', 'fpr')
pred.nn <- prediction(hiv.nn$predictions, hiv.svm$labels)
perf.nn <- performance(pred.nn, 'tpr', 'fpr')
plot(perf.svm, lty=3, col="red",main="SVMs and NNs for prediction of
HIV-1 coreceptor usage")
plot(perf.nn, lty=3, col="blue",add=TRUE)
plot(perf.svm, avg="vertical", lwd=3, col="red",
spread.estimate="stderror",plotCI.lwd=2,add=TRUE)
plot(perf.nn, avg="vertical", lwd=3, col="blue",
spread.estimate="stderror",plotCI.lwd=2,add=TRUE)
legend(0.6,0.6,c('SVM','NN'),col=c('red','blue'),lwd=3)